#TODO specify the Hydra config setup and all individual parameters

defaults:
  - _self_
  - env: control
  - random: seed1
  - algorithm: baseline

hydra:
  sweep:
    dir: hydra_output/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.runtime.choices.algorithm}/${hydra.runtime.choices.random}
  job:
    chdir: True

name: ${hydra:runtime.choices.algorithm}_${hydra:runtime.choices.random}

seed_name: ${hydra:runtime.choices.random}

model_dir: ./
cbp_dir: ./cbp
cbp_log_freq: 100

progress_bar: True

env:
  frame_stack: 4
  subproc_vecenv: True
  gamma: 0.99
  decorr: True
  seed: ${random.seed}

algorithm:
  training_frames: ???

  tensorboard_log: ${hydra:runtime.cwd}/${hydra:sweep.dir}/tensorboard

  settings:
    learning_starts: ???
    buffer_size: ???
    batch_size: ???
    target_update_interval: ???

    gradient_steps: 2
    replay_buffer_kwargs:
      n_step: 3
    prioritized_er_beta0_initial: 0.45
    gamma: 0.99
    
    learning_rate: ???

    loss_fn: 'huber'
    max_grad_norm: 10

    eps_decay_frames: ???

    policy_kwargs:
      noisy_linear: False
      linear_kwargs: {}
      optimizer_kwargs:
        betas: [0.9, 0.999]
        eps: null  # will be set in the code

checkpoint_dir: ./checkpoints/
checkpoint_freq: ???

eval:
  # eval during training
  evalcallback: True

  eval_freq: ???

  n_eval_episodes: 10
  dir: ./eval
  best_model_dir: ./

wandb:
  project: Rainbow
  name: ${name}
  group: ${hydra:runtime.choices.algorithm}
  mode: online
  dir: ${hydra:runtime.cwd}/${hydra:sweep.dir}
  monitor_gym: False # auto-upload the videos of agents playing the game

wandb_gradient_save_freq: ???